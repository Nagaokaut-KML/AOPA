{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from segment_dataloader import Segment_dataloader\n",
    "from torch.utils.data import DataLoader\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 3\n",
    "trainset = Segment_dataloader(mode=\"train\")\n",
    "valset = Segment_dataloader(mode=\"val\")\n",
    "train_loader = DataLoader(trainset, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(valset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from model.cnn_lstm import CNN_LSTM\n",
    "\n",
    "cuda = True\n",
    "if cuda:\n",
    "    device = torch.device(\"cuda\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    \n",
    "model = CNN_LSTM(100,25, 300, 13)\n",
    "model = model.to(device)\n",
    "\n",
    "# weight_path = \"/home2/kataoka/echigo_hudagami/iwaka/operation/model_weight/lstm/operation_weight_exp1.pth\"\n",
    "# checkpoint = torch.load(weight_path)\n",
    "# model.load_state_dict(checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using poly LR Scheduler!\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "import torch\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "from utils.loss import SegmentationLosses\n",
    "from utils.lr_scheduler import LR_Scheduler\n",
    "from utils.saver import Saver\n",
    "from utils.metrics import Evaluator\n",
    "optimizer = torch.optim.Adam(model.parameters(), weight_decay=4e-5)\n",
    "criterion = SegmentationLosses(cuda=cuda).build_loss(mode=\"focal\")\n",
    "evaluator = Evaluator(13)\n",
    "scheduler = LR_Scheduler(\"poly\", 0.001, 100, len(train_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def training(epoch, best_pred):\n",
    "    train_loss = 0.0\n",
    "    model.train()\n",
    "    tbar = tqdm(train_loader)\n",
    "    num_img_tr = len(train_loader)\n",
    "    for i, sample in enumerate(tbar):\n",
    "        image, target = sample['image'], sample['label']\n",
    "        if cuda:\n",
    "            image, target = image.cuda(), target.cuda()\n",
    "        scheduler(optimizer, i, epoch, best_pred)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(image)\n",
    "        loss = criterion(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss += loss.item()\n",
    "        tbar.set_description('Train loss: %.7f' % (train_loss / (i + 1)))\n",
    "\n",
    "        # Show 10 * 3 inference results each epoch\n",
    "        if i % (num_img_tr // 10) == 0:\n",
    "            global_step = i + num_img_tr * epoch\n",
    "\n",
    "    print('[Epoch: %d, numImages: %5d]' % (epoch, i * batch_size + image.data.shape[0]))\n",
    "    print('Loss: %.7f' % train_loss)\n",
    "    return train_loss\n",
    "\n",
    "def validation(epoch, best_pred, best_loss):\n",
    "    model.eval()\n",
    "    evaluator.reset()\n",
    "    tbar = tqdm(val_loader, desc='\\r')\n",
    "    test_loss = 0.0\n",
    "    for i, sample in enumerate(tbar):\n",
    "        image, target = sample['image'], sample['label']\n",
    "        if cuda:\n",
    "            image, target = image.cuda(), target.cuda()\n",
    "        with torch.no_grad():\n",
    "            output = model(image)\n",
    "        \n",
    "        loss = criterion(output, target)\n",
    "        test_loss += loss.item()\n",
    "        tbar.set_description('Test loss: %.7f' % (test_loss / (i + 1)))\n",
    "        pred = output.data.cpu().numpy()\n",
    "        target = target.cpu().numpy()\n",
    "        # 三次元配列をargmaxで二次元配列にできないから、batchを１づつargmaxにする\n",
    "        \n",
    "        reshape_pred = np.zeros((2,100),dtype=int)\n",
    "        for index in range(batch_size):\n",
    "            reshape_pred[index] = np.argmax(pred[index], axis=1)\n",
    "        # Add batch sample into evaluator\n",
    "        evaluator.add_batch(target, reshape_pred)\n",
    "\n",
    "    # Fast test during the training\n",
    "    Acc = evaluator.Pixel_Accuracy()\n",
    "    Acc_class = evaluator.Pixel_Accuracy_Class()\n",
    "    mIoU = evaluator.Mean_Intersection_over_Union()\n",
    "    FWIoU = evaluator.Frequency_Weighted_Intersection_over_Union()\n",
    "    print('Validation:')\n",
    "    print('[numImages: %5d]' % (i * batch_size + image.data.shape[0]))\n",
    "    print(\"Acc:{}, Acc_class:{}, mIoU:{}, fwIoU: {}\".format(Acc, Acc_class, mIoU, FWIoU))\n",
    "    print('Loss: %.7f' % test_loss)\n",
    "\n",
    "    new_pred = mIoU\n",
    "    if new_pred > best_pred:\n",
    "        is_best = True\n",
    "        best_pred = new_pred\n",
    "    if test_loss < best_loss:\n",
    "        print(\"improve {0} to {1}. save checkpoint.\".format(best_loss, test_loss))\n",
    "        torch.save(model.state_dict(), \"./model_weigth/cnn_lstm/weight_exp{}.pth\".format(exp))\n",
    "        best_loss = test_loss\n",
    "    return best_pred, best_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/18194 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start learning.\n",
      "\n",
      "=>Epoches 0, learning rate = 0.0010,                 previous best = 0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='mean' instead.\n",
      "  warnings.warn(warning.format(ret))\n",
      "Train loss: 0.0030327:  13%|█▎        | 2333/18194 [2:46:23<19:22:27,  4.40s/it]"
     ]
    }
   ],
   "source": [
    "#学習\n",
    "exp = 1\n",
    "\n",
    "print(\"start learning.\")\n",
    "best_pred = 0\n",
    "best_loss = 1000\n",
    "t_losses = []\n",
    "v_losses = []\n",
    "for epoch in range(10):\n",
    "    #t_loss, v_loss = np.array([0.0]), np.array([0.0])\n",
    "    t_loss = training(epoch, best_pred)\n",
    "    best_pred, best_loss = validation(epoch, best_pred, best_loss)\n",
    "    t_losses += [t_loss]\n",
    "    v_losses += [best_loss]\n",
    "#     if v_loss < best_loss:\n",
    "#         best_loss = v_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(t_losses)\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('loss')\n",
    "plt.grid()\n",
    "plt.savefig('./train_loss.png') \n",
    "\n",
    "plt.figure()\n",
    "plt.plot(v_losses)\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('loss')\n",
    "plt.grid()\n",
    "plt.savefig('./v_loss.png') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t_losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 0, 0])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "input = torch.randn(3, 5, requires_grad=True)\n",
    "target = torch.empty(3, dtype=torch.long).random_(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 5])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sat Jan 18 13:13:24 2020       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 410.48                 Driver Version: 410.48                    |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  GeForce RTX 208...  Off  | 00000000:65:00.0  On |                  N/A |\n",
      "| 44%   45C    P8     9W / 250W |     45MiB / 10988MiB |      0%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   1  GeForce RTX 208...  Off  | 00000000:B3:00.0 Off |                  N/A |\n",
      "| 29%   43C    P8    12W / 250W |     11MiB / 10989MiB |      0%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                       GPU Memory |\n",
      "|  GPU       PID   Type   Process name                             Usage      |\n",
      "|=============================================================================|\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
